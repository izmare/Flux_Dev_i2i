{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/izmare/Flux_Dev_i2i/blob/main/FluxDevi2i.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Setup TotoroUI and Download Models\n",
        "import os\n",
        "import subprocess\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Change directory to /content\n",
        "%cd /content\n",
        "\n",
        "# Clone the repository if it hasn't been done yet\n",
        "if not os.path.exists('/content/TotoroUI'):\n",
        "    !git clone -b totoro3 https://github.com/camenduru/ComfyUI /content/TotoroUI\n",
        "\n",
        "# Change directory to /content/TotoroUI\n",
        "%cd /content/TotoroUI\n",
        "\n",
        "# Install necessary packages\n",
        "!pip install -q torchsde einops diffusers accelerate xformers==0.0.27.post2\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "# Model download options\n",
        "download_flux_dev = True  #@param {type:\"boolean\"}\n",
        "download_flux_schnell = False  #@param {type:\"boolean\"}\n",
        "\n",
        "# Download the FLUX.1-dev model\n",
        "if download_flux_dev:\n",
        "    if not os.path.exists('/content/TotoroUI/models/unet/flux1-dev-fp8.safetensors'):\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/flux1-dev-fp8.safetensors -d /content/TotoroUI/models/unet -o flux1-dev-fp8.safetensors\n",
        "    if not os.path.exists('/content/TotoroUI/models/vae/ae.sft'):\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/ae.sft -d /content/TotoroUI/models/vae -o ae.sft\n",
        "    if not os.path.exists('/content/TotoroUI/models/clip/clip_l.safetensors'):\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/clip_l.safetensors -d /content/TotoroUI/models/clip -o clip_l.safetensors\n",
        "    if not os.path.exists('/content/TotoroUI/models/clip/t5xxl_fp8_e4m3fn.safetensors'):\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/t5xxl_fp8_e4m3fn.safetensors -d /content/TotoroUI/models/clip -o t5xxl_fp8_e4m3fn.safetensors\n",
        "\n",
        "# Download the FLUX.1-schnell model\n",
        "if download_flux_schnell:\n",
        "    if not os.path.exists('/content/TotoroUI/models/unet/flux1-schnell-fp8.safetensors'):\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-schnell/resolve/main/flux1-schnell-fp8.safetensors -d /content/TotoroUI/models/unet -o flux1-schnell-fp8.safetensors\n",
        "    if not os.path.exists('/content/TotoroUI/models/vae/ae_schnell.sft'):\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-schnell/resolve/main/ae.sft -d /content/TotoroUI/models/vae -o ae_schnell.sft\n",
        "    if not os.path.exists('/content/TotoroUI/models/clip/clip_l_schnell.safetensors'):\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-schnell/resolve/main/clip_l.safetensors -d /content/TotoroUI/models/clip -o clip_l_schnell.safetensors\n",
        "    if not os.path.exists('/content/TotoroUI/models/clip/t5xxl_fp8_schnell.safetensors'):\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-schnell/resolve/main/t5xxl_fp8_e4m3fn.safetensors -d /content/TotoroUI/models/clip -o t5xxl_fp8_schnell.safetensors\n",
        "\n",
        "# Display loading bar for progress\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "\n",
        "for i in tqdm(range(100), desc=\"Loading Models...\"):\n",
        "    time.sleep(0.05)\n",
        "clear_output()\n",
        "\n",
        "# Import necessary modules\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import nodes\n",
        "from nodes import NODE_CLASS_MAPPINGS\n",
        "from totoro_extras import nodes_custom_sampler\n",
        "from totoro_extras import nodes_post_processing\n",
        "from totoro import model_management\n",
        "\n",
        "# Initialize model components\n",
        "DualCLIPLoader = NODE_CLASS_MAPPINGS[\"DualCLIPLoader\"]()\n",
        "UNETLoader = NODE_CLASS_MAPPINGS[\"UNETLoader\"]()\n",
        "RandomNoise = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"RandomNoise\"]()\n",
        "BasicGuider = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicGuider\"]()\n",
        "KSamplerSelect = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"KSamplerSelect\"]()\n",
        "BasicScheduler = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicScheduler\"]()\n",
        "SamplerCustomAdvanced = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"SamplerCustomAdvanced\"]()\n",
        "VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
        "VAEEncode = NODE_CLASS_MAPPINGS[\"VAEEncode\"]()\n",
        "EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
        "ImageScaleToTotalPixels = nodes_post_processing.NODE_CLASS_MAPPINGS[\"ImageScaleToTotalPixels\"]()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    clip = DualCLIPLoader.load_clip(\"t5xxl_fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"flux\")[0]\n",
        "    unet = UNETLoader.load_unet(\"flux1-dev-fp8.safetensors\", \"fp8_e4m3fn\")[0]\n",
        "    vae = VAELoader.load_vae(\"ae.sft\")[0]\n",
        "\n",
        "# Function to convert input image to PNG if not already\n",
        "def convert_to_png(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    if img.format != 'PNG':\n",
        "        png_path = os.path.splitext(image_path)[0] + '.png'\n",
        "        img.save(png_path)\n",
        "        return png_path\n",
        "    return image_path\n",
        "\n",
        "# Function to generate an incremental file name\n",
        "def generate_incremental_filename(directory, base_name='output', ext='.png'):\n",
        "    i = 0\n",
        "    while os.path.exists(f\"{directory}/{base_name}_{i:04d}{ext}\"):\n",
        "        i += 1\n",
        "    return f\"{directory}/{base_name}_{i:04d}{ext}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Image Generation with Guidance Scale and Conversion to PNG\n",
        "import torch\n",
        "import random\n",
        "import string\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Input fields\n",
        "positive_prompt = \"A serene mountain landscape\"  #@param {type:\"string\"}\n",
        "width = 512  #@param {type:\"slider\", min:0, max:2048, step:64}\n",
        "height = 1024  #@param {type:\"slider\", min:0, max:2048, step:64}\n",
        "seed = 0  #@param {type:\"number\"}\n",
        "steps = 20  #@param {type:\"slider\", min:10, max:100, step:5}\n",
        "sampler_name = \"euler\"  #@param [\"euler\", \"ddim\", \"plms\", \"heun\"]\n",
        "scheduler = \"simple\"  #@param [\"simple\", \"linear\", \"cosine\"]\n",
        "guidance_scale = 3.5  #@param {type:\"slider\", min:1.0, max:10.0, step:0.1}\n",
        "image_dir = \"/content/test.png\"  #@param {type:\"string\"}\n",
        "\n",
        "# Convert image to PNG if necessary\n",
        "image_path = convert_to_png(image_dir)\n",
        "\n",
        "# Generate random seed if 0\n",
        "if seed == 0:\n",
        "    seed = random.randint(1, 1e6)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Initialize latent image\n",
        "latent_image = EmptyLatentImage.new_latent(width, height)\n",
        "\n",
        "# Create and configure noise generator\n",
        "random_noise = RandomNoise.generate_noise(width, height, steps, scheduler, seed)\n",
        "\n",
        "# Image generation process\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(steps), desc=\"Generating Image...\"):\n",
        "        latent_image = unet(latent_image, random_noise[i])\n",
        "        latent_image = BasicGuider.apply_guidance_scale(latent_image, guidance_scale)\n",
        "        latent_image = KSamplerSelect.select(latent_image, sampler_name)\n",
        "\n",
        "# Decode latent image to RGB\n",
        "decoded_image = VAEDecode.decode(latent_image)\n",
        "\n",
        "# Scale image to desired size\n",
        "scaled_image = ImageScaleToTotalPixels.scale(decoded_image, width * height)\n",
        "\n",
        "# Save output image with incremental file name\n",
        "output_path = generate_incremental_filename(\"/content\", \"output\")\n",
        "scaled_image.save(output_path)\n",
        "\n",
        "# Display the generated image\n",
        "display(Image.open(output_path))\n",
        "print(f\"Image saved at {output_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wouwe7HxeKG_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}